shiny::runApp()
shiny::runApp()
shiny::runApp()
setwd('E:/Google Drive/DataScienceCapstoneNLP')
datadrcty <- './Data/final/'
language <- 'en_US'
blogs <- paste0(datadrcty,language,'/',language,'.blogs.txt')
news <- paste0(datadrcty,language,'/',language,'.news.txt')
twitter <- paste0(datadrcty,language,'/',language,'.twitter.txt')
profList <- 'en_US.profanity.txt'
source('prepareFile.R')
preNews <- prepareFile(news)
preBlogs <- prepareFile(blogs)
preTwitter <- prepareFile(twitter)
preTotal <- paste(c(preNews,preBlogs,preTwitter))
source('reduceData.R')
redData <- reduceData(preTotal,customFile = profList)
smp_size <- floor(0.005 * length(redData))
set.seed(123)
train_ind <- sample(seq_len(length(redData)), size = smp_size)
training <- redData[train_ind]
setwd('D:/Documents/GoogleDrive/DataScienceCapstoneNLP')
datadrcty <- './Data/final/'
language <- 'en_US'
blogs <- paste0(datadrcty,language,'/',language,'.blogs.txt')
news <- paste0(datadrcty,language,'/',language,'.news.txt')
twitter <- paste0(datadrcty,language,'/',language,'.twitter.txt')
profList <- 'en_US.profanity.txt'
source('prepareFile.R')
preNews <- prepareFile(news)
preBlogs <- prepareFile(blogs)
setwd('D:/Documents/GoogleDrive/DataScienceCapstoneNLP')
datadrcty <- './Data/final/'
language <- 'en_US'
blogs <- paste0(datadrcty,language,'/',language,'.blogs.txt')
news <- paste0(datadrcty,language,'/',language,'.news.txt')
twitter <- paste0(datadrcty,language,'/',language,'.twitter.txt')
profList <- 'en_US.profanity.txt'
source('prepareFile.R')
preNews <- prepareFile(news)
preBlogs <- prepareFile(blogs)
preTwitter <- prepareFile(twitter)
preTotal <- paste(c(preNews,preBlogs,preTwitter))
source('reduceData.R')
redData <- reduceData(preTotal,customFile = profList)
smp_size <- floor(0.005 * length(redData))
set.seed(123)
train_ind <- sample(seq_len(length(redData)), size = smp_size)
training <- redData[train_ind]
grams <- data.table(Grams=character())
docs <- training
n <- 1
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
require(stringi)
require(stringr)
require(data.table)
grams <- data.table(Grams=character())
docs <- training
n <- 1
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
unigrams<-grams
grams <- data.table(Grams=character())
docs <- training
n <- 2
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
if (n > 1){
grams <- grams[,sum(Frame_1, Frame_2, na.rm=T),with = T, by = Grams]
splitGrams <- strsplit(grams$Grams, ' ')
splitGrams <- t(as.data.table(splitGrams))
nGrams <- as.data.table(cbind(splitGrams, grams$V1))
} else{
nGrams <- grams
}
bigrams <- nGrams
grams <- data.table(Grams=character())
docs <- training
n <- 3
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
if (n > 1){
grams <- grams[,sum(Frame_1, Frame_2, Frame_3, na.rm=T),with = T, by = Grams]
splitGrams <- strsplit(grams$Grams, ' ')
splitGrams <- t(as.data.table(splitGrams))
nGrams <- as.data.table(cbind(splitGrams, grams$V1))
} else{
nGrams <- grams
}
trigrams <- nGrams
grams <- data.table(Grams=character())
docs <- training
n <- 4
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
if (n > 1){
grams <- grams[,sum(Frame_1, Frame_2, Frame_3, Frame_4, na.rm=T),with = T, by = Grams]
splitGrams <- strsplit(grams$Grams, ' ')
splitGrams <- t(as.data.table(splitGrams))
nGrams <- as.data.table(cbind(splitGrams, grams$V1))
} else{
nGrams <- grams
}
quadrigrams <- nGrams
grams <- data.table(Grams=character())
docs <- training
n <- 5
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
if (n > 1){
grams <- grams[,sum(Frame_1, Frame_2, Frame_3, Frame_4, Frame_5, na.rm=T),with = T, by = Grams]
splitGrams <- strsplit(grams$Grams, ' ')
splitGrams <- t(as.data.table(splitGrams))
nGrams <- as.data.table(cbind(splitGrams, grams$V1))
} else{
nGrams <- grams
}
quintigrams <- nGrams
bigrams$V3 <- as.numeric(bigrams$V3)
trigrams$V4<- as.numeric(trigrams$V4)
quadrigrams$V5 <- as.numeric(quadrigrams$V5)
quintigrams$V6 <- as.numeric(quintigrams$V6)
unigrams$probabilities <- unigrams$Frame_1/nrow(unigrams)
bigrams$probabilities <- bigrams$V3/nrow(bigrams)
trigrams$probabilities <- trigrams$V4/nrow(trigrams)
quadrigrams$probabilities <- quadrigrams$V5/nrow(quadrigrams)
quintigrams$probabilities <- quintigrams$V6/nrow(quintigrams)
unigrams$MLE <- unigrams$Frame_1/sum(unigrams$Frame_1)
MLE <- numeric(nrow(bigrams))
for (i in 1:nrow(bigrams)){
x <- bigrams$V3[i]
y <- unigrams$Frame_1[which(unigrams$Grams==bigrams$V1[i])]
MLE[i] <- x/y
}
bigrams$MLE <- MLE
MLE <- numeric(nrow(trigrams))
for (i in 1:nrow(trigrams)){
x <- trigrams$V4[i]
y <- bigrams$V3[which(bigrams$V1==trigrams$V1[i]&bigrams$V2==trigrams$V2[i])]
MLE[i] <- x/y
}
trigrams$MLE <- MLE
MLE <- numeric(nrow(quadrigrams))
for (i in 1:nrow(quadrigrams)){
x <- quadrigrams$V5[i]
y <- trigrams$V4[which(trigrams$V1==quadrigrams$V1[i]&trigrams$V2==quadrigrams$V2[i]&trigrams$V3==quadrigrams$V3[i])]
MLE[i] <- x/y
}
quadrigrams$MLE <- MLE
MLE <- numeric(nrow(quintigrams))
for (i in 1:nrow(quintigrams)){
x <- quintigrams$V6[i]
y <- quadrigrams$V5[which(quadrigrams$V1==quintigrams$V1[i]&quadrigrams$V2==quintigrams$V2[i]&quadrigrams$V3==quintigrams$V3[i]&quadrigrams$V4==quintigrams$V4[i])]
MLE[i] <- x/y
}
quintigrams$MLE <- MLE
unigrams <- setorder(unigrams, -MLE, -probabilities)
bigrams <- setorder(bigrams, -MLE, -probabilities)
trigrams <- setorder(trigrams, -MLE, -probabilities)
quadrigrams <- setorder(quadrigrams, -MLE, -probabilities)
quintigrams <- setorder(quintigrams, -MLE, -probabilities)
head(quintigrams,20)
saveRDS(unigrams, 'NL/unigrams.rds')
saveRDS(bigrams, 'NL/bigrams.rds')
saveRDS(trigrams, 'NL/trigrams.rds')
saveRDS(quadrigrams, 'NL/quadrigrams.rds')
saveRDS(quintigrams, 'NL/quintigrams.rds')
saveRDS(unigrams, 'NL/2/unigrams.rds')
saveRDS(bigrams, 'NL/2/bigrams.rds')
saveRDS(trigrams, 'NL/2/trigrams.rds')
saveRDS(quadrigrams, 'NL/2/quadrigrams.rds')
saveRDS(quintigrams, 'NL/2/quintigrams.rds')
saveRDS(unigrams, 'NL/2/unigrams.rds')
saveRDS(bigrams, 'NL/2/bigrams.rds')
saveRDS(trigrams, 'NL/2/trigrams.rds')
saveRDS(quadrigrams, 'NL/2/quadrigrams.rds')
saveRDS(quintigrams, 'NL/2/quintigrams.rds')
shiny::runApp('NL')
shiny::runApp('NL')
shiny::runApp('NL')
shiny::runApp('NL')
smp_size <- floor(0.05 * length(redData))
set.seed(123)
train_ind <- sample(seq_len(length(redData)), size = smp_size)
train_ing <- redData[train_ind]
smp_size <- floor(0.05 * length(redData))
set.seed(123)
train_ind <- sample(seq_len(length(redData)), size = smp_size)
training <- redData[train_ind
]
grams <- data.table(Grams=character())
docs <- training
n <- 1
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
if (n > 1){
grams <- grams[,sum(Frame_1,na.rm=T),with = T, by = Grams]
splitGrams <- strsplit(grams$Grams, ' ')
splitGrams <- t(as.data.table(splitGrams))
nGrams <- as.data.table(cbind(splitGrams, grams$V1))
} else{
nGrams <- grams
}
unigrams <- nGrams
grams <- data.table(Grams=character())
docs <- training
n <- 2
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
if (n > 1){
grams <- grams[,sum(Frame_1, Frame_2,na.rm=T),with = T, by = Grams]
splitGrams <- strsplit(grams$Grams, ' ')
splitGrams <- t(as.data.table(splitGrams))
nGrams <- as.data.table(cbind(splitGrams, grams$V1))
} else{
nGrams <- grams
}
bigrams <- nGrams
grams <- data.table(Grams=character())
docs <- training
n <- 3
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
if (n > 1){
grams <- grams[,sum(Frame_1, Frame_2, Frame_3,na.rm=T),with = T, by = Grams]
splitGrams <- strsplit(grams$Grams, ' ')
splitGrams <- t(as.data.table(splitGrams))
nGrams <- as.data.table(cbind(splitGrams, grams$V1))
} else{
nGrams <- grams
}
trigrams <- nGrams
grams <- data.table(Grams=character())
docs <- training
n <- 5
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
if (n > 1){
grams <- grams[,sum(Frame_1, Frame_2, Frame_3, Frame_4,Frame_5,na.rm=T),with = T, by = Grams]
splitGrams <- strsplit(grams$Grams, ' ')
splitGrams <- t(as.data.table(splitGrams))
nGrams <- as.data.table(cbind(splitGrams, grams$V1))
} else{
nGrams <- grams
}
quintigrams <- nGrams
grams <- data.table(Grams=character())
docs <- training
n <- 4
for(i in 1:n){
frame <- str_extract_all(docs, paste0('\\<',paste0(rep("[a-z]+\\s", n-1),collapse = ''),"[a-z]+\\>",collapse = ''))
frame <- as.data.table(table(unlist(frame)))
frame <- setnames(frame, c('V1', 'N'),c('Grams', paste0('Frame_',i)))
grams <- merge(grams, frame, by = 'Grams', all.x=T, all.y=T)
if(i < n){
docs <- gsub('^\\s*[a-z]+\\s', '', docs)
}
}
if (n > 1){
grams <- grams[,sum(Frame_1, Frame_2, Frame_3, Frame_4,na.rm=T),with = T, by = Grams]
splitGrams <- strsplit(grams$Grams, ' ')
splitGrams <- t(as.data.table(splitGrams))
nGrams <- as.data.table(cbind(splitGrams, grams$V1))
} else{
nGrams <- grams
}
quadrigrams <- nGrams
bigrams$V3 <- as.numeric(bigrams$V3)
trigrams$V4 <- as.numeric(trigrams$V4)
quadrigrams$V5 <- as.numeric(quadrigrams$V5)
quintigrams$V6 <- as.numeric(quintigrams$V6)
unigrams$MLE <- unigrams$Frame_1/sum(unigrams$Frame_1)
unigrams <- setorder(unigrams, -MLE)
saveRDS(unigrams, 'unigrams.rds')
MLE <- numeric(nrow(bigrams))
for (i in 1:nrow(bigrams)){
x <- bigrams$V3[i]
y <- unigrams$Frame_1[which(unigrams$Grams==bigrams$V1[i])]
MLE[i] <- x/y
}
bigrams$MLE <- MLE
bigrams <- setorder(bigrams, -MLE)
saveRDS(bigrams, 'bigrams.rds')
MLE <- numeric(nrow(trigrams))
for (i in 1:nrow(trigrams)){
x <- trigrams$V4[i]
y <- bigrams$V3[which(bigrams$V1==trigrams$V1[i]&bigrams$V2==trigrams$V2[i])]
MLE[i] <- x/y
}
install.packages("e1071")
load("C:/Users/thoma_000/Downloads/week49.Rdata")
View(week49.data1)
load("C:/Users/thoma_000/Downloads/quiz4.Rdata")
library(randomForest)
set.seed(99)
library(caret)inTrain<-createDataPartition(y=solu.300.alldescr.noNa.no0var$measured,p=0.75,list = F)
training<-solu.300.alldescr.noNa.no0var[inTrain,]
testing<-solu.300.alldescr.noNa.no0var[-inTrain,]
library(caret)
inTrain<-createDataPartition(y=quiz4.data1$response,p=0.8,list = F)
training<-quiz4.data1[inTrain,]
testing<-quiz4.data1[-inTrain,]
solu.rf <- randomForest(response ~ ., data = training, importance = TRUE)
solu.rf
predict(testing, solu.rf)
predict(solu.rf, newdata = tresting)
predict(solu.rf, newdata = testing)
test.pred <- predict(solu.rf, newdata = cyp.testing)
test.pred <- predict(solu.rf, newdata =testing)
test.cm <- table(test.pred,testing$response)
(test.cm[2,1]+test.cm[1,2])/nrow(cyp.testing)*100
(test.cm[2,1]+test.cm[1,2])/nrow(testing)*100
load("C:/Users/thoma_000/Downloads/quiz4.Rdata")
library(randomForest)
set.seed(99)
library(caret)
training<-quiz4.data1[inTrain,]
inTrain<-createDataPartition(y=quiz4.data1$response,p=0.8,list = F)
training<-quiz4.data1[inTrain,]
testing<-quiz4.data1[-inTrain,]
solu.rf <- randomForest(response ~ ., data = training, importance = TRUE)
solu.rf
test.pred <- predict(solu.rf, newdata = testing)
test.cm <- table(test.pred,testing$response)
(test.cm[2,1]+test.cm[1,2])/nrow(testing)*100
install.packages("pROC")
library(pROC)
roc.curve <- plot.roc(testing$CYP1A2, testing.classProb[,2], percent=TRUE, ci=TRUE)
roc.curve <- plot.roc(testing$response, testing.classProb[,2], percent=TRUE, ci=TRUE)
testing.classProb <- predict(solu.rf, newdata = testing, type = "prob")
roc.curve <- plot.roc(testing$response, testing.classProb[,2], percent=TRUE, ci=TRUE)
auc(roc.curve)
varImpPlot(solu.rf)
training<-quiz4.data2[inTrain,]
testing<-quiz4.data2[-inTrain,]
solu.pls <- plsr(response ~ ., ncomp=10, data=training, validation="LOO", scale=T)
library(plsr)
install.package('plsr')
install.packages('plsr')
library(plsr)
library(pls)
install.packages('pls')
library(pls)
solu.pls <- plsr(response ~ ., ncomp=10, data=training, validation="LOO", scale=T)
solu.pls
summary(solu.pls)
solu.pls <- lm(response ~ ., ncomp=10, data=training)
solu.pls <- lm(response ~ ., data=training)
summary(solu.pls)
set.seed(44)
library(e1071)
solu.svm <- best.svm(x=training[,-1], y=training$response, gamma=c(0.01,0.1,1), cost=c(4,8,10), probability=T, tunecontrol=tune.control(cross=3))
solu.svm
library(ggplot2)
library(reshape2)
library(gplots)
library(data.table)
library(ggmap)
library(randomForest)
setwd('D:\\Documents\\GoogleDrive\\Udacity - data Analyst\\Udacity---Project-4-')
data_variables <- read.csv('training_set.csv')
data_labels <- read.csv('training_labels.csv')
data <- merge(data_variables,
data_labels,
by = 'id')
colnames(data)
data[['amount_tsh']]
var <- 'amount_tsh'
data[[var]]
univariate <- function(data, var){
p <- ggplot(data, aes(x = data[[var]])) +
geom_histogram() +
labs(x = var)
print(p)
}
univariate(data, 'amount_tsh')
uvar <- function(data, varname){
p <- ggplot(data, aes(x = data[[varname]])) +
geom_histogram()
print(p)
}
uvar(data, 'amount_tsh')
uvar <- function(data, x){
p <- ggplot(data, aes(x = data[[x]])) +
geom_histogram()
print(p)
}
uvar(data, 'amount_tsh')
uvar <- function(data, varname){
d <- as.data.frame(data[[varname]])
p <- ggplot(d, aes(x=d)) +
geom_histogram()
print(p)
}
uvar(data, 'amount_tsh')
d <- as.data.frame(data[[varname]])
uvar <- function(data, varname){
p <- ggplot(data, aes(x = data[[varname]])) +
geom_histogram()
print(p)
}
uvar(data, 'amount_tsh')
print(data, 'amount_tsh')
p <- ggplot(data, aes(x = data[['amount_tsh']])) +
geom_histogram()
print(p)
?function
)
